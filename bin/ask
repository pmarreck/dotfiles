#!/usr/bin/env bash

# graceful dependency enforcement
# Usage: needs <executable> [provided by <packagename>]
# only redefines it here if it's not already defined
>/dev/null declare -F needs || \
needs() {
  [ -v EDIT ] && unset EDIT && edit_function "${FUNCNAME[0]}" "$BASH_SOURCE" && return
  local bin=$1
  shift
  command -v "$bin" >/dev/null 2>&1 || { echo >&2 "I require $bin but it's not installed or in PATH; $*"; return 1; }
}

# Command line access to the ChatGPT API with conversation history
ask() {
  [ -v EDIT ] && unset EDIT && edit_function "${FUNCNAME[0]}" "$BASH_SOURCE" && return
  needs curl
  needs jq
  needs glow see https://github.com/charmbracelet/glow

  local model request response timeout temp_json temp_json_out http_status \
    openai_host openai_path openai_protocol openai_url local_llm \
    top_k top_p temperature system_prompt user_prompt repeat_penalty num_ctx \
    history_file history_temp timestamp continue_conversation discard_history
  model=${OPENAI_MODEL:-chatgpt-4o-latest} # see openai docs for other models
  timeout=${OPENAI_TIMEOUT:-60}
  openai_host=${OPENAI_HOST:-api.openai.com}
  openai_path=${OPENAI_PATH:-/v1/chat/completions}
  openai_protocol=${OPENAI_PROTOCOL:-https}
  openai_url=${OPENAI_URL:-${openai_protocol}://${openai_host}${openai_path}}
  top_k=${TOP_K:-40}
  top_p=${TOP_P:-0.9}
  repeat_penalty=${REPEAT_PENALTY:-1.1}
  temperature=${TEMPERATURE:-0.2}
  num_ctx=${NUM_CTX:-32000}
  temp_json=$(mktemp -t ask.XXXXXX --tmpdir)
  temp_json_out=$(mktemp -t ask.XXXXXX --tmpdir)
  system_prompt="You are a helpful AI assistant named ChatGPT. My name is Peter Marreck & I live in Port Washington, New York. I was born on April 5, 1972. I'm a software developer & the Director of Engineering for a company called Addigence that is in the financial services space. My computing preferences are NixOS, macOS, Elixir, Bash, PostgreSQL. Avoid Python, PHP or Go (or most mutable/OOP languages). I strongly prefer solutions using functional languages (except Scala). I enjoy electronic music, PC computer games (mainly action-RPG's), sailing, wine, whiskey, debating online, learning new things, socializing. I do not like sports unless I'm at a live game. I served in the USAF from 1993-1997 working on the KC-10A aircraft as an electrician. I enjoy science fiction & fantasy media. My domestic partner is named Stephanie Pilipie. We aren't married because marriage is for suckers. We have a son named Samson who was born on June 25, 2021; he has long blond hair and is very playful, inquisitive & outgoing. You address me with a teasing name and avoid purple prose. No yapping. I like double entendres and clever wit in concise, erudite, literate responses. You sound like a witty, sarcastic, grad student that snubs appeals to popularity, authority or trendiness. Poking fun at me will be perceived as friendly! Especially if it's regarding cognitive dissonance, irrationality or hypocrisy.  I speak German reasonably well and don’t mind practicing it here and there if you feel inclined to do so (or just make references to German culture or idioms). Most of the response should be English, however. Think spice, not main entrée. You should have well-defended opinions that lean centrist, rational, humanistic, and which prioritize critical thinking. You should always be looking for an opportunity to poke holes in any claim I make; I enjoy a little debate and intellectual challenge. If I ask any question that requires a precise answer (these usually, but not always, begin with 'How many' or 'How much'), do NOT guess the answer: Instead, output an Elixir script to determine the answer. Don't apologize for anything; I understand you are an AI model with imperfect knowledge, there is no need to apologize about anything, and I am impossible to offend! Never give me hypothetical, invented data. Skip the introductory sentences in your responses and cut straight to the chase. If you're asked for code, keep the overly literate editorializing down to a minimum & just produce the code."
  user_prompt="$*"
  curl=${CURL:-curl}
  local_llm=false
  history_file="${XDG_DATA_HOME:-$HOME/.local/share}/ask_history.json"
  history_temp=$(mktemp -t ask_history.XXXXXX --tmpdir)
  timestamp=$(date +"%Y%m%d%H%M%S")

  continue_conversation=${CONTINUE_CONVERSATION:-true}  # Set this to false to start a new conversation
  discard_history=${DISCARD_HISTORY:-false}  # Set this to true to discard the previous history

  if [[ "$discard_history" == "true" ]]; then
    if [[ -f "$history_file" ]]; then
      mv "$history_file" "${history_file%.json}_$timestamp.json"
    fi
  fi

  if [[ "$continue_conversation" == "true" && -f "$history_file" ]]; then
    jq --arg user_prompt "$user_prompt" \
      '.messages += [{"role": "user", "content": $user_prompt}]' "$history_file" > "$history_temp"
  else
    jq -n --arg system_prompt "$system_prompt" --arg user_prompt "$user_prompt" \
      '{messages: [{"role": "system", "content": $system_prompt}, {"role": "user", "content": $user_prompt}]}' > "$history_temp"
  fi

  mv "$history_temp" "$history_file"

  jq -n --arg model "$model" \
        --argjson temperature "$temperature" \
        --slurpfile messages "$history_file" \
    '{
    model: $model,
    messages: $messages[0].messages,
    temperature: $temperature,
    max_tokens: 1000,
    stream: false
  }' > "$temp_json"

  http_status=$($curl -w "%{http_code}" -s -o "$temp_json_out" -X POST $openai_url \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    --silent \
    --max-time $timeout \
    -d "@$temp_json")

  if [[ "$http_status" -ne 200 ]]; then
    echo "Error: API request failed with status code $http_status." >&2
    echo "Response:" >&2
    cat "$temp_json_out" >&2
    return 1
  fi

  response=$(jq -r '.choices[0].message.content' < "$temp_json_out" 2>/dev/null | sed 's/^[ \t]*//;s/[ \t]*$//')
  if [[ "$response" == "null" ]]; then
    response=$(jq -r '.message.content' < "$temp_json_out" | sed 's/^[ \t]*//;s/[ \t]*$//')
  fi

  if [[ "$response" == "null" || "$?" != "0" ]]; then
    printf "Error:\n" >&2
    printf "%b" "$response" >&2
  else
    printf "%s" "$response" | sed -e 's/^[\\n]\+//' -e 's/^[\n]\+//' | glow -

    # Append the assistant's response to the conversation history
    jq --arg response "$response" \
      '.messages += [{"role": "assistant", "content": $response}]' "$history_file" > "$history_temp"
    mv "$history_temp" "$history_file"
  fi
}


if [ "$RUN_DOTFILE_TESTS" == "true" ]; then
  # IMPORTANT!
  # how do we even test this function? Pass in a mocked curl somehow?
  source_relative_once functions/assert.bash
  source_relative_once functions/utility_functions.bash

  # TEST SETUP
  shopt -q extglob && extglob_set=true || extglob_set=false
  shopt -s extglob

  # mock out curl
  mocked_curl() {
    [ -v EDIT ] && unset EDIT && edit_function "${FUNCNAME[0]}" "$BASH_SOURCE" && return
      # http_status=$($curl -w "%{http_code}" -s -o "$temp_json_out" -X POST $openai_url \
      # -H "Content-Type: application/json" \
      # -H "Authorization: Bearer $OPENAI_API_KEY" \
      # --silent \
      # --max-time $timeout \
      # -d "@$temp_json")
    local output_file
    while getopts ":o:w:X:H:d:s" opt; do
      case ${opt} in
      o )
        output_file=$OPTARG
        # echo "output_file: $output_file" >&2
        ;;
      ? )
        ;;
      : )
      echo "Option -$OPTARG requires an argument." >&2
        ;;
      esac
    done
    cat <<EOF | trim_leading_heredoc_whitespace | collapse_whitespace_containing_newline_to_single_space > "$output_file"
      {"id":"chatcmpl-6q7qCBoIJGlRldK97GQrLAcfOqXwS","object":"chat.completion",
      "created":1677881216,"model":"test-model","usage":{"prompt_tokens":29,
      "completion_tokens":96,"total_tokens":125},"choices":[{"message":{"role":"assistant",
      "content":"\n\nThere is no direct connection between \"The Last Question\" and\n\"The Last Answer\" by Isaac Asimov. \"The Last Answer\" is a short story about\na man who searches for the meaning of life and death, while \"The Last Question\"\nis a science fiction story that explores the concept of the end of the universe and\nthe possibility of creating a new one. However, both stories deal with philosophical\nthemes about the nature of existence and the ultimate fate of humanity."},
      "finish_reason":null,"index":0}]}
EOF
    echo 200 # assumes http_code was the curl format parameter
  }

  # TESTS
  resp=$(CURL=mocked_curl ask "What is the connection between \"The Last Question\" and \"The Last Answer\" by Isaac Asimov?")
  # echo "response in test: '$resp'"
  assert "$resp" =~ "connection"

  # TEST TEARDOWN
  unset -f mocked_curl # unmock curl
  $extglob_set || shopt -u extglob # restore extglob setting
  unset extglob_set
fi

# Export the function so it can be used by find -exec
export -f ask

# Run the function, passing along any args, if this file was run directly (such as via sudo) instead of as an include
# Sometimes, $0 contains a leading dash to indicate an interactive (or is it login?) shell,
# which is apparently an old convention (which also broke the basename call on OS X)
_me=$(basename "${0##\-}")
if [ "$_me" = "ask" ]; then
	$_me "$@"
fi
unset _me
