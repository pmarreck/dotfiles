#!/usr/bin/env bash

# graceful dependency enforcement
# Usage: needs <executable> [provided by <packagename>]
# only redefines it here if it's not already defined
>/dev/null declare -F needs || \
needs() {
  [ -v EDIT ] && unset EDIT && edit_function "${FUNCNAME[0]}" "$BASH_SOURCE" && return
  local bin=$1
  shift
  command -v "$bin" >/dev/null 2>&1 || { echo >&2 "I require $bin but it's not installed or in PATH; $*"; return 1; }
}

# Command line access to the ChatGPT API with conversation history
ask() {
  [ -v EDIT ] && unset EDIT && edit_function "${FUNCNAME[0]}" "$BASH_SOURCE" && return
  needs curl
  needs jq
  needs glow see https://github.com/charmbracelet/glow

  local model request response timeout temp_json temp_json_out http_status \
    openai_host openai_path openai_protocol openai_url local_llm \
    top_k top_p temperature system_prompt user_prompt repeat_penalty num_ctx \
    history_file history_temp timestamp continue_conversation discard_history
  # model=${OPENAI_MODEL:-chatgpt-4o-latest} # see openai docs for other models
  model=${OPENAI_MODEL:-gpt-4o-2024-08-06} # see openai docs for other models
  timeout=${OPENAI_TIMEOUT:-60}
  openai_host=${OPENAI_HOST:-api.openai.com}
  openai_path=${OPENAI_PATH:-/v1/chat/completions}
  openai_protocol=${OPENAI_PROTOCOL:-https}
  openai_url=${OPENAI_URL:-${openai_protocol}://${openai_host}${openai_path}}
  top_k=${TOP_K:-40}
  top_p=${TOP_P:-0.9}
  repeat_penalty=${REPEAT_PENALTY:-1.1}
  temperature=${TEMPERATURE:-0.2}
  num_ctx=${NUM_CTX:-32000}
  temp_json=$(mktemp -t ask.XXXXXX --tmpdir)
  temp_json_out=$(mktemp -t ask.XXXXXX --tmpdir)
  system_prompt="${LLM_SYSTEM_PROMPT:-You are a helpful AI assistant named ChatGPT.}"
  user_prompt="$*"
  curl=${CURL:-curl}
  local_llm=false
  history_file="${XDG_DATA_HOME:-$HOME/.local/share}/ask_history.json"
  history_temp=$(mktemp -t ask_history.XXXXXX --tmpdir)
  timestamp=$(date +"%Y%m%d%H%M%S")

  continue_conversation=${CONTINUE_CONVERSATION:-true}  # Set this to false to start a new conversation
  discard_history=${DISCARD_HISTORY:-false}  # Set this to true to discard the previous history

  if [[ "$discard_history" == "true" ]]; then
    if [[ -f "$history_file" ]]; then
      mv "$history_file" "${history_file%.json}_$timestamp.json"
    fi
  fi

  if [[ "$continue_conversation" == "true" && -f "$history_file" ]]; then
    jq --arg user_prompt "$user_prompt" \
      '.messages += [{"role": "user", "content": $user_prompt}]' "$history_file" > "$history_temp"
  else
    jq -n --arg system_prompt "$system_prompt" --arg user_prompt "$user_prompt" \
      '{messages: [{"role": "system", "content": $system_prompt}, {"role": "user", "content": $user_prompt}]}' > "$history_temp"
  fi

  mv "$history_temp" "$history_file"

  tools='[
    {
      "type": "function",
      "function": {
        "name": "get_location",
        "description": "Get the user location. Call this whenever you need to know their location, for example when they ask for the local weather but you need their precise location first.",
        "parameters": {
          "type": "object",
          "properties": {}
        }
      }
    },
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get the weather at the user location.",
        "parameters": {
          "type": "object",
          "properties": {
            "zip_code": {
              "type": "string",
              "description": "The user zip code."
            }
          }
        }
      }
    }
  ]'
  jq -n --arg model "$model" \
        --argjson temperature "$temperature" \
        --argjson tools "$tools" \
        --slurpfile messages "$history_file" \
    '{
    model: $model,
    messages: $messages[0].messages,
    temperature: $temperature,
    max_tokens: 1000,
    tools: $tools,
    stream: false
  }' > "$temp_json"

  http_status=$($curl -w "%{http_code}" -s -o "$temp_json_out" -X POST $openai_url \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    --silent \
    --max-time $timeout \
    -d "@$temp_json")

  if [[ "$http_status" -ne 200 ]]; then
    echo "Error: API request failed with status code $http_status." >&2
    echo "Response:" >&2
    cat "$temp_json_out" >&2
    return 1
  fi

  response=$(jq -r '.choices[0].message.content' < "$temp_json_out" 2>/dev/null | sed 's/^[ \t]*//;s/[ \t]*$//')
  if [[ "$response" == "null" ]]; then
    response=$(jq -r '.message.content' < "$temp_json_out" | sed 's/^[ \t]*//;s/[ \t]*$//')
  fi

  if [[ "$response" == "null" || "$?" != "0" ]]; then
    printf "Error:\n" >&2
    printf "%b" "$response" >&2
  else
    printf "%s" "$response" | sed -e 's/^[\\n]\+//' -e 's/^[\n]\+//' | glow -

    # Append the assistant's response to the conversation history
    jq --arg response "$response" \
      '.messages += [{"role": "assistant", "content": $response}]' "$history_file" > "$history_temp"
    mv "$history_temp" "$history_file"
  fi
}


if [ "$RUN_DOTFILE_TESTS" == "true" ]; then
  # IMPORTANT!
  # how do we even test this function? Pass in a mocked curl somehow?
  source_relative_once functions/assert.bash
  source_relative_once functions/utility_functions.bash

  # TEST SETUP
  history_file="${XDG_DATA_HOME:-$HOME/.local/share}/ask_history.json"
  # back up conversation file
  if [[ -f "$history_file" ]]; then
    cp "$history_file" "${history_file%.json}_backup.json"
  fi
  shopt -q extglob && extglob_set=true || extglob_set=false
  shopt -s extglob

  # mock out curl
  mocked_curl() {
    [ -v EDIT ] && unset EDIT && edit_function "${FUNCNAME[0]}" "$BASH_SOURCE" && return
      # http_status=$($curl -w "%{http_code}" -s -o "$temp_json_out" -X POST $openai_url \
      # -H "Content-Type: application/json" \
      # -H "Authorization: Bearer $OPENAI_API_KEY" \
      # --silent \
      # --max-time $timeout \
      # -d "@$temp_json")
    local output_file
    while getopts ":o:w:X:H:d:s" opt; do
      case ${opt} in
      o )
        output_file=$OPTARG
        # echo "output_file: $output_file" >&2
        ;;
      ? )
        ;;
      : )
      echo "Option -$OPTARG requires an argument." >&2
        ;;
      esac
    done
    cat <<EOF | trim_leading_heredoc_whitespace | collapse_whitespace_containing_newline_to_single_space > "$output_file"
      {"id":"chatcmpl-6q7qCBoIJGlRldK97GQrLAcfOqXwS","object":"chat.completion",
      "created":1677881216,"model":"test-model","usage":{"prompt_tokens":29,
      "completion_tokens":96,"total_tokens":125},"choices":[{"message":{"role":"assistant",
      "content":"\n\nThere is no direct connection between \"The Last Question\" and\n\"The Last Answer\" by Isaac Asimov. \"The Last Answer\" is a short story about\na man who searches for the meaning of life and death, while \"The Last Question\"\nis a science fiction story that explores the concept of the end of the universe and\nthe possibility of creating a new one. However, both stories deal with philosophical\nthemes about the nature of existence and the ultimate fate of humanity."},
      "finish_reason":null,"index":0}]}
EOF
    echo 200 # assumes http_code was the curl format parameter
  }

  # TESTS
  resp=$(CURL=mocked_curl ask "What is the connection between \"The Last Question\" and \"The Last Answer\" by Isaac Asimov?")
  # echo "response in test: '$resp'"
  assert "$resp" =~ "connection"

  # TEST TEARDOWN
  unset -f mocked_curl # unmock curl
  $extglob_set || shopt -u extglob # restore extglob setting
  unset extglob_set
  # restore original history file after removing the test one
  if [[ -f "${history_file%.json}_backup.json" ]]; then
    rm -f "$history_file"
    mv "${history_file%.json}_backup.json" "$history_file"
  fi
fi

# Export the function so it can be used by find -exec
export -f ask

# Run the function, passing along any args, if this file was run directly (such as via sudo) instead of as an include
# Sometimes, $0 contains a leading dash to indicate an interactive (or is it login?) shell,
# which is apparently an old convention (which also broke the basename call on OS X)
_me=$(basename "${0##\-}")
if [ "$_me" = "ask" ]; then
	$_me "$@"
fi
unset _me
